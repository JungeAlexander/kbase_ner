{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "expired-essay",
   "metadata": {},
   "source": [
    "# Load SageMaker GroundTruth annotation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "musical-authorization",
   "metadata": {},
   "source": [
    "## Load task manifest file mapping text sample IDs to text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "likely-privilege",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import codecs\n",
    "from dataclasses import dataclass\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import Dict, List\n",
    "\n",
    "import spacy\n",
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "narrow-irish",
   "metadata": {},
   "outputs": [],
   "source": [
    "manifest_path = Path(\"annotations/glue-dir-kbase-dev-sagemaker-ground-truth-labeling-clone/annotations/intermediate/1/annotations.manifest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controlling-crown",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert manifest_path.is_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "needed-wedding",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_text_raw = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contemporary-syntax",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(manifest_path, \"rt\") as fin:\n",
    "    for line in fin:\n",
    "        columns = line.split(\"\\t\")\n",
    "        index = int(columns[0])\n",
    "        text = \"\\t\".join(columns[1:-1])\n",
    "        _ = columns[-1]  # no idea what this column is\n",
    "        assert index not in index_to_text_raw\n",
    "        index_to_text_raw[index] = text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aerial-tackle",
   "metadata": {},
   "source": [
    "## Load annotation for given sample text IDs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "radio-texas",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_dir = Path(\"annotations/glue-dir-kbase-dev-sagemaker-ground-truth-labeling-clone/annotations/worker-response/iteration-1/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "north-dividend",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert annotations_dir.is_dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strange-manitoba",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_annotation_raw = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controlling-sauce",
   "metadata": {},
   "outputs": [],
   "source": [
    "for annotations_subdir in annotations_dir.iterdir():\n",
    "    index = int(annotations_subdir.name)\n",
    "    for i, annotations_file in enumerate(annotations_subdir.iterdir()):\n",
    "        assert i == 0, f\"found more than one annotation in {annotations_subdir}\"\n",
    "        with open(annotations_file, \"rt\") as fin:\n",
    "            j = json.load(fin)\n",
    "        assert index not in index_to_annotation_raw\n",
    "        answers = j[\"answers\"]\n",
    "        assert len(answers) == 1\n",
    "        entities = answers[0]['answerContent']['crowd-entity-annotation']['entities']\n",
    "        index_to_annotation_raw[index] = entities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greater-vector",
   "metadata": {},
   "source": [
    "## Merge text and annotation whole removing episode IDs from text and adjusting entity positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southern-newport",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class EntityMatch:\n",
    "    label: str\n",
    "    start_offset: int\n",
    "    end_offset: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "light-subscription",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Doc:\n",
    "    id_: str\n",
    "    text: str\n",
    "    annotations: List[EntityMatch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "muslim-cheese",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = []\n",
    "for index, annotation_raw in index_to_annotation_raw.items():\n",
    "    text_raw = index_to_text_raw[index]\n",
    "    text = codecs.unicode_escape_decode(text_raw)[0]\n",
    "    id_, text = text.split(\"\\n\", 1)\n",
    "    id_offset = len(id_) + 1  # +1 due to newline which was stripped of before\n",
    "    entity_matches = []\n",
    "    for a in annotation_raw:\n",
    "        match = EntityMatch(label=a[\"label\"],\n",
    "                            start_offset=a[\"startOffset\"] - id_offset,\n",
    "                            end_offset=a[\"endOffset\"] - id_offset)\n",
    "        entity_matches.append(match)\n",
    "    doc = Doc(id_=id_, text=text, annotations=entity_matches)\n",
    "    docs.append(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "square-parker",
   "metadata": {},
   "source": [
    "## Create spacy Doc objects, load entity annotations and write DocBin to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electrical-hurricane",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "functioning-treasurer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spacy English NER labels https://spacy.io/models/en#en_core_web_sm-labels\n",
    "# spacy glossary: https://github.com/explosion/spaCy/blob/master/spacy/glossary.py\n",
    "label_to_spacy_ner_label = {\n",
    "    \"Book\": \"WORK_OF_ART\",\n",
    "    \"Person\": \"PERSON\",\n",
    "    \"Software\": \"PRODUCT\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "third-source",
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_docs = []\n",
    "check_ents = {}\n",
    "for d in docs:\n",
    "    spacy_doc = nlp(d.text.encode('utf8','replace').decode('utf8')) # TODO is this necessary?\n",
    "    my_ents = []\n",
    "    for a in d.annotations:\n",
    "        ent = spacy_doc.char_span(a.start_offset,\n",
    "                            a.end_offset,\n",
    "                            label=label_to_spacy_ner_label[a.label])\n",
    "        if ent is None:\n",
    "            # FIXME investigate where this happens instead of just skipping\n",
    "            continue\n",
    "        my_ents.append(ent)\n",
    "    spacy_doc.user_data = {\"id\": d.id_}\n",
    "    # TODO keep spacy_doc.ents from default pipeline by setting default=\"unmodified\" below?\n",
    "    spacy_doc.set_ents(my_ents, default=\"missing\") \n",
    "    spacy_docs.append(spacy_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opened-egypt",
   "metadata": {},
   "source": [
    "## Visualize for sanity checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sealed-campus",
   "metadata": {},
   "outputs": [],
   "source": [
    "#spacy_doc.ents = my_ents\n",
    "displacy.render(spacy_doc, style=\"ent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modular-scout",
   "metadata": {},
   "source": [
    "## Split into train/dev/test per podcast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "christian-christian",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_bin = spacy.tokens.DocBin(docs=spacy_docs)\n",
    "doc_bin.to_disk(output_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
